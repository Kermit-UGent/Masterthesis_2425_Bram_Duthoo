{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Pad naar de bestanden\n",
    "food_file_path = r\"C:\\Users\\bramd_finhsgu\\OneDrive - UGent\\Thesis\\Thesis_bestanden\\__MACOSX\\foodb_2020_04_07_json\\Food.json\"\n",
    "content_file_path = r\"C:\\Users\\bramd_finhsgu\\OneDrive - UGent\\Thesis\\Thesis_bestanden\\__MACOSX\\foodb_2020_04_07_json\\Content.json\"\n",
    "\n",
    "# Food ID instellen waarop gefilterd moet worden\n",
    "selected_food_id = 506  # Vervang dit nummer met het gewenste food_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Food.json DataFrame opgeslagen als: C:\\Users\\bramd_finhsgu\\OneDrive - UGent\\Thesis\\id_name_foodb.csv\n",
      "Food.json eerste paar regels:\n",
      "    id       name\n",
      "0  303      Bison\n",
      "1  310  Wild boar\n",
      "2  316    Buffalo\n",
      "3  334    Chicken\n",
      "4  353  Mule deer\n"
     ]
    }
   ],
   "source": [
    "# Animal foods filteren om id's te bekomen\n",
    "filtered_food_data = []\n",
    "with open(food_file_path, \"r\", encoding=\"utf-8\") as food_file:\n",
    "    for line in food_file:\n",
    "        try:\n",
    "            item = json.loads(line.strip())\n",
    "            if item.get(\"food_group\") == \"Animal foods\":\n",
    "                filtered_food_data.append({\"id\": item.get(\"id\"), \"name\": item.get(\"name\")})\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Fout bij het verwerken van een regel in food.json: {e}\")\n",
    "\n",
    "food_df = pd.DataFrame(filtered_food_data)\n",
    "\n",
    "food_output_path = r\"C:\\Users\\bramd_finhsgu\\OneDrive - UGent\\Thesis\\id_name_foodb.csv\"\n",
    "food_df.to_csv(food_output_path, index=False)\n",
    "print(f\"\\nFood.json DataFrame opgeslagen als: {food_output_path}\")\n",
    "\n",
    "# Eerste paar regels van de DataFrame weergeven\n",
    "print(\"Food.json eerste paar regels:\")\n",
    "print(food_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_data eerste paar regels:\n",
      "     id  food_id orig_food_id              orig_food_common_name  source_id  \\\n",
      "0  4690      506         0551      Beef brisket, soaked in brine          2   \n",
      "1  4691      506         0551      Beef brisket, soaked in brine          2   \n",
      "2  4692      506         0436  Beef, brisket, anterior part, raw          2   \n",
      "3  4693      506         0436  Beef, brisket, anterior part, raw          2   \n",
      "4  4694      506         0437    Beef, brisket, middle part, raw          2   \n",
      "\n",
      "  orig_source_id  orig_source_name source_type orig_content orig_unit  \\\n",
      "0           0001    Protein, total    Nutrient      21000.0  mg/100 g   \n",
      "1           0002  Protein, total-N    Nutrient       3400.0  mg/100 g   \n",
      "2           0001    Protein, total    Nutrient      17600.0  mg/100 g   \n",
      "3           0002  Protein, total-N    Nutrient       2800.0  mg/100 g   \n",
      "4           0001    Protein, total    Nutrient      15900.0  mg/100 g   \n",
      "\n",
      "  standard_content  \n",
      "0          21000.0  \n",
      "1           3400.0  \n",
      "2          17600.0  \n",
      "3           2800.0  \n",
      "4          15900.0  \n"
     ]
    }
   ],
   "source": [
    "# content.json filteren op basis van food_id's & relevante kolommen selecteren\n",
    "content_data = []\n",
    "with open(content_file_path, \"r\", encoding=\"utf-8\") as content_file:\n",
    "    for line in content_file:\n",
    "        try:\n",
    "            item = json.loads(line.strip())\n",
    "            if item.get(\"food_id\") == selected_food_id:  # Filter op de geselecteerde food_id\n",
    "                # Alleen de gewenste kolommen opnemen\n",
    "                filtered_item = {\n",
    "                    \"id\": item.get(\"id\"),\n",
    "                    \"food_id\": item.get(\"food_id\"),\n",
    "                    \"orig_food_id\": item.get(\"orig_food_id\"),\n",
    "                    \"orig_food_common_name\": item.get(\"orig_food_common_name\"),\n",
    "                    \"source_id\": item.get(\"source_id\"),\n",
    "                    \"orig_source_id\": item.get(\"orig_source_id\"),\n",
    "                    \"orig_source_name\": item.get(\"orig_source_name\"),\n",
    "                    \"source_type\": item.get(\"source_type\"),\n",
    "                    \"orig_content\": item.get(\"orig_content\"),\n",
    "                    \"orig_unit\": item.get(\"orig_unit\"),\n",
    "                    \"standard_content\": item.get(\"standard_content\"),\n",
    "                }\n",
    "                content_data.append(filtered_item)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Fout bij het verwerken van een regel in content.json: {e}\")\n",
    "\n",
    "# Data omzetten naar een Pandas DataFrame\n",
    "content_df = pd.DataFrame(content_data)\n",
    "print(\"content_data eerste paar regels:\")\n",
    "print(content_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id zal per definitie altijd een waarde hebben, daarnaast wordt er gefilterd op food_id waardoor dit ook altijd een waarde zal hebben. orig_food_id is de id van orig_food_common_name, nulwaarden hiervoor zijn dus niet problematisch zolang orig_food_common_name een waarde heeft. Deze worden gebruikt om binnenin de food_id een verdere distinctie te maken tussen verschillende onderdelen van het geheel, bv food_id 506 = beef & binnenin beef zijn er verschillende onderdelen zoals brisket, sirloin, minced meat, fat etc. orig_source_name & orig_source_id worden dan gebruikt om de verschillende componenten te kenmerken zoals glutamic acid, glucose etc. Source_type wordt gebruikt om een distinctie te maken tussen nutrients (FAT, PROTEIN, ...) & compounds (Glutamic acid, glucose, ...). Orig_content, orig_unit & standard_content worden gebruikt om de waarde van elke nutrient/compound te bewaren en quantificeren. Tenslotte blijft source_id over wat nog steeds een compleet mysterie voor me blijft, de naam lijkt belangrijk, maar ik kan geen enkele connectie vinden met een andere parameter en ik heb nog geen antwoord ontvangen van de eigenaars van de database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aantal unieke waarden per kolom:\n",
      "id                       138620\n",
      "food_id                       1\n",
      "orig_food_id                908\n",
      "orig_food_common_name       908\n",
      "source_id                 49997\n",
      "orig_source_id              241\n",
      "orig_source_name            205\n",
      "source_type                   2\n",
      "orig_content              10720\n",
      "orig_unit                     6\n",
      "standard_content          10154\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Bereken het aantal unieke waarden per kolom\n",
    "unique_values_per_column = content_df.apply(lambda col: col.nunique())\n",
    "\n",
    "# Toon de resultaten\n",
    "print(\"Aantal unieke waarden per kolom:\")\n",
    "print(unique_values_per_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Totaal aantal unieke orig_source_name's: 205\n",
      "Aantal orig_source_name met meerdere orig_source_id's: 34\n",
      "\n",
      "Voorbeelden van orig_source_name met bijbehorende orig_source_id's (eerste 5):\n",
      "Alanine: ['0248', '513']\n",
      "Arginine: ['0246', '511']\n",
      "Ash: ['0012', '207']\n",
      "Aspartic acid: ['0249', '514']\n",
      "Carotene, beta: ['0016', '321']\n",
      "\n",
      "Totaal aantal extra gebruikte orig_source_id's: 36\n",
      "\n",
      "Totaal aantal unieke orig_source_id's: 241\n",
      "Aantal orig_source_id met meerdere orig_source_name's: 0\n"
     ]
    }
   ],
   "source": [
    "# Controle A: Welke `orig_source_id`'s horen bij een `orig_source_name`?\n",
    "source_name_to_ids = content_df.groupby(\"orig_source_name\")[\"orig_source_id\"].unique()\n",
    "multiple_ids_per_name = source_name_to_ids[source_name_to_ids.apply(len) > 1]\n",
    "\n",
    "total_unique_source_names = content_df[\"orig_source_name\"].nunique()\n",
    "print(f\"\\nTotaal aantal unieke orig_source_name's: {total_unique_source_names}\")\n",
    "print(f\"Aantal orig_source_name met meerdere orig_source_id's: {len(multiple_ids_per_name)}\")\n",
    "\n",
    "if not multiple_ids_per_name.empty:\n",
    "    print(\"\\nVoorbeelden van orig_source_name met bijbehorende orig_source_id's (eerste 5):\")\n",
    "    for name, ids in multiple_ids_per_name.head().items():\n",
    "        print(f\"{name}: {list(ids)}\")\n",
    "\n",
    "# Bereken het aantal extra gebruikte ID's\n",
    "total_ids_used = sum(source_name_to_ids.apply(len))  # Totaal aantal ID's gekoppeld aan namen\n",
    "extra_ids = total_ids_used - total_unique_source_names  # Extra ID's gebruikt\n",
    "print(f\"\\nTotaal aantal extra gebruikte orig_source_id's: {extra_ids}\")\n",
    "\n",
    "# Controle B: Welke `orig_source_name`'s horen bij een `orig_source_id`?\n",
    "source_id_to_names = content_df.groupby(\"orig_source_id\")[\"orig_source_name\"].unique()\n",
    "multiple_names_per_id = source_id_to_names[source_id_to_names.apply(len) > 1]\n",
    "\n",
    "total_unique_source_ids = content_df[\"orig_source_id\"].nunique()\n",
    "print(f\"\\nTotaal aantal unieke orig_source_id's: {total_unique_source_ids}\")\n",
    "print(f\"Aantal orig_source_id met meerdere orig_source_name's: {len(multiple_names_per_id)}\")\n",
    "\n",
    "if not multiple_names_per_id.empty:\n",
    "    print(\"\\nVoorbeelden van orig_source_id met bijbehorende orig_source_name's (eerste 5):\")\n",
    "    for source_id, names in multiple_names_per_id.head().items():\n",
    "        print(f\"{source_id}: {list(names)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sommige orig_source_names zijn dus gekoppeld aan meerdere ID's, maar niet vice versa, dus dit vormt geen probleem. !!!Inspecteren per source_name waarom dit zo is, en indien dit gewoon een foutje is kunnen de ID's gecollapsed worden naar 1 waarde, of gewoon zo gelaten worden en de informatie van meerdere ID's onthouden voor latere verdere analyses/koppelingen te maken met de content.json dataset. KIJKEN OF DIT GEBRUIK AFHANKELIJK IS VAN EEN ANDERE PARAMETER, wss source_type of orig_unit aangezien dit de enige kolommen zijn met slechts een aantal verschillende soort waardes en aangezien er voor 32 names 2 ID's gebruikt worden en 2 names 3 ID's wijst dit waarschijnlijk op een heel eenvoudige relatie (indien die er is)!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage waarin orig_content gelijk is aan standard_content: 62.76%\n",
      "\n",
      "Aantal rijen waarin orig_content niet gelijk is aan standard_content: 51618\n",
      "\n",
      "Voorbeelden van verschillende waarden:\n",
      "           id   orig_content standard_content\n",
      "13771  118472  280.831739962           1175.0\n",
      "13772  118473  213.432122371            893.0\n",
      "13773  118474   323.61376673           1354.0\n",
      "13774  118475  315.009560229           1318.0\n",
      "13775  118476  196.940726577            824.0\n"
     ]
    }
   ],
   "source": [
    "# Controle of orig_content gelijk is aan standard_content\n",
    "equal_orig_standard = (content_df[\"orig_content\"] == content_df[\"standard_content\"])\n",
    "\n",
    "# Percentage van gelijkheid\n",
    "percentage_equal = equal_orig_standard.mean() * 100\n",
    "print(f\"\\nPercentage waarin orig_content gelijk is aan standard_content: {percentage_equal:.2f}%\")\n",
    "\n",
    "# Rijen waar de waarden verschillen (indien nodig)\n",
    "different_values = content_df[~equal_orig_standard]\n",
    "print(f\"\\nAantal rijen waarin orig_content niet gelijk is aan standard_content: {len(different_values)}\")\n",
    "if not different_values.empty:\n",
    "    print(\"\\nVoorbeelden van verschillende waarden:\")\n",
    "    print(different_values[[\"id\",\"orig_content\", \"standard_content\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!controleer of dit verschil in orig_content tov standard content afhankelijk is van de source type of andere parameter, idem zoals hierboven!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage ontbrekende waarden per kolom:\n",
      "id                        0.000000\n",
      "food_id                   0.000000\n",
      "orig_food_id             36.174434\n",
      "orig_food_common_name     0.200548\n",
      "source_id                 0.000000\n",
      "orig_source_id           40.297937\n",
      "orig_source_name         40.297937\n",
      "source_type               0.000000\n",
      "orig_content             35.978935\n",
      "orig_unit                35.978935\n",
      "standard_content         35.978935\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_percentage = (content_df.isnull().mean() * 100)\n",
    "print(\"\\nPercentage ontbrekende waarden per kolom:\")\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Een nulwaarde in één van de content-kolommen (orig_content, orig_unit, standard_content) impliceert een nulwaarde in de andere twee.\n",
      "✅ Een nulwaarde in orig_source_name impliceert altijd een nulwaarde in orig_source_id (en vice versa).\n",
      "\n",
      "Aantal rijen oorspronkelijk: 138620\n",
      "Aantal rijen na filtering: 82758\n",
      "Aantal verwijderde rijen: 55862\n",
      "\n",
      "Percentage ontbrekende waarden per kolom na filtering:\n",
      "id                       0.0\n",
      "food_id                  0.0\n",
      "orig_food_id             0.0\n",
      "orig_food_common_name    0.0\n",
      "source_id                0.0\n",
      "orig_source_id           0.0\n",
      "orig_source_name         0.0\n",
      "source_type              0.0\n",
      "orig_content             0.0\n",
      "orig_unit                0.0\n",
      "standard_content         0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sinds ontbrekende waardes in een van de content kolommen geen waardevolle datapunten zijn worden deze eruit gefilterd.\n",
    "# Idem voor source_id & source_name kolom. Veranderen indien source_id toch een betekenis heeft in deze context!\n",
    "\n",
    "# Controle 1: Correlatie tussen content kolommen\n",
    "content_missing = content_df[\"orig_content\"].isnull()\n",
    "unit_missing = content_df[\"orig_unit\"].isnull()\n",
    "standard_missing = content_df[\"standard_content\"].isnull()\n",
    "\n",
    "# Controle of ontbrekende waarden in één van de content-kolommen altijd ontbreken in de andere twee\n",
    "content_correlation = (content_missing == unit_missing) & (unit_missing == standard_missing)\n",
    "\n",
    "if content_correlation.all():\n",
    "    print(\"✅ Een nulwaarde in één van de content-kolommen (orig_content, orig_unit, standard_content) impliceert een nulwaarde in de andere twee.\")\n",
    "else:\n",
    "    print(\"❌ Inconsistenties gevonden in de content-kolommen. Controleer de data.\")\n",
    "\n",
    "# Controle 2: Correlatie tussen source kolommen\n",
    "source_name_missing = content_df[\"orig_source_name\"].isnull()\n",
    "source_id_missing = content_df[\"orig_source_id\"].isnull()\n",
    "\n",
    "# Controle of een nulwaarde in orig_source_name altijd gepaard gaat met een nulwaarde in orig_source_id\n",
    "source_correlation = source_name_missing == source_id_missing\n",
    "\n",
    "if source_correlation.all():\n",
    "    print(\"✅ Een nulwaarde in orig_source_name impliceert altijd een nulwaarde in orig_source_id (en vice versa).\")\n",
    "else:\n",
    "    print(\"❌ Inconsistenties gevonden in de source-kolommen. Controleer de data.\")\n",
    "\n",
    "# Aantal rijen vóór filtering\n",
    "original_row_count = len(content_df)\n",
    "\n",
    "# Verwijder rijen waar een van de kolommen nulwaarden bevat\n",
    "columns_to_check = [\"orig_content\", \"orig_unit\", \"standard_content\", \"orig_source_name\", \"orig_source_id\"]\n",
    "filtered_df = content_df.dropna(subset=columns_to_check, how=\"any\")\n",
    "\n",
    "# Aantal rijen na filtering\n",
    "filtered_row_count = len(filtered_df)\n",
    "\n",
    "# Bereken het percentage ontbrekende waarden opnieuw per kolom\n",
    "missing_percentage = filtered_df.isnull().mean() * 100\n",
    "\n",
    "# Toon het resultaat\n",
    "print(f\"\\nAantal rijen oorspronkelijk: {original_row_count}\")\n",
    "print(f\"Aantal rijen na filtering: {filtered_row_count}\")\n",
    "print(f\"Aantal verwijderde rijen: {original_row_count - filtered_row_count}\")\n",
    "print(\"\\nPercentage ontbrekende waarden per kolom na filtering:\")\n",
    "print(missing_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aantal unieke waarden per kolom:\n",
      "id                       82758\n",
      "food_id                      1\n",
      "orig_food_id               907\n",
      "orig_food_common_name      907\n",
      "source_id                  139\n",
      "orig_source_id             240\n",
      "orig_source_name           204\n",
      "source_type                  2\n",
      "orig_content             10622\n",
      "orig_unit                    6\n",
      "standard_content         10056\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Bereken het aantal unieke waarden per kolom\n",
    "unique_values_per_column2 = filtered_df.apply(lambda col: col.nunique())\n",
    "\n",
    "# Toon de resultaten\n",
    "print(\"Aantal unieke waarden per kolom:\")\n",
    "print(unique_values_per_column2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
